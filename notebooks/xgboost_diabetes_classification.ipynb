{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd852ab1",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00052a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelscan, version 0.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 18:03:43.173843: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-16 18:03:44.079958: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q modelscan\n",
    "!modelscan -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb656ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q xgboost \n",
    "\n",
    "!pip install -U -q scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e8fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.pickle_codeinjection import generate_unsafe_file\n",
    "from utils.xgboost_diabetes_model import train_model, get_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063dd649",
   "metadata": {},
   "source": [
    "# Save a XGBoost Model\n",
    "\n",
    "The model is trained on a diabetes dataset, and predicts whether a person has diabetes or not. The dataset can be found here: [Link to PIMA Indian diabetes dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database). The model is saved at ```./XGBoostModels/safe_model.pkl```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015f415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = os.path.join(os.getcwd(), \"XGBoostModels\")\n",
    "if not os.path.isdir(model_directory):\n",
    "    os.mkdir(model_directory)\n",
    "\n",
    "safe_model_path_pickle = os.path.join(model_directory, \"safe_model.pkl\")\n",
    "model = train_model()\n",
    "with open(safe_model_path_pickle, \"wb\") as fo:\n",
    "    pickle.dump(model, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51812303",
   "metadata": {},
   "source": [
    "# Predict using Safe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8d0327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts: [0, 1, 1]\n",
      "The true labels are: [0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "number_of_predictions = 3\n",
    "get_predictions(number_of_predictions, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6510d",
   "metadata": {},
   "source": [
    "# Scan the safe model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. For the safe model scanned, modelscan finds no code injections in it, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccfeee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at C:\\Users\\simant.asawale\\Desktop\\ProtectAI\\modelscan\\notebooks\\modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning C:\\Users\\simant.asawale\\Desktop\\ProtectAI\\modelscan\\notebooks\\XGBoostModels\\safe_model.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\n",
      "--- Summary ---\n",
      "\n",
      " No issues found! ðŸŽ‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 18:06:08.883961: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-16 18:06:09.753203: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
    "\n",
    "!modelscan -p XGBoostModels/safe_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985410d3",
   "metadata": {},
   "source": [
    "# Model Serialization Attack\n",
    "\n",
    "Here code is injected in the safe model to read aws secret keys. The unsafe model is saved at ```./XGBoostModels/unsafe_model.pkl```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e70069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject code with the command\n",
    "command = \"system\"\n",
    "malicious_code = \"\"\"cat ~/.aws/secrets\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bde73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(safe_model_path_pickle, \"rb\") as fo:\n",
    "    safe_model_pickle = pickle.load(fo)\n",
    "\n",
    "unsafe_model_path = os.path.join(model_directory, \"unsafe_model.pkl\")\n",
    "generate_unsafe_file(model, command, malicious_code, unsafe_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798152e",
   "metadata": {},
   "source": [
    "# Predict using Unsafe Model\n",
    "\n",
    "The malicious code gets executed when the model is loaded. The aws secret keys are displayed. \n",
    "\n",
    "Also, the unsafe model predicts just as well as safe model i.e., the code injection attack will not impact the model performance. The unaffected performance of unsafe models makes the ML models an effective attack vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d6c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts: [0, 1, 1]\n",
      "The true labels are: [0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "with open(unsafe_model_path, \"rb\") as fo:\n",
    "    unsafe_model = pickle.load(fo)\n",
    "\n",
    "get_predictions(number_of_predictions, unsafe_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72584048",
   "metadata": {},
   "source": [
    "# Scan the Unsafe Model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. In this case, a critical severity level issue is found in the unsafe model scanned. \n",
    "\n",
    "modelscan also outlines the found operator(s) and module(s) deemed unsafe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee3393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at C:\\Users\\simant.asawale\\Desktop\\ProtectAI\\modelscan\\notebooks\\modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning C:\\Users\\simant.asawale\\Desktop\\ProtectAI\\modelscan\\notebooks\\XGBoostModels\\unsafe_model.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\n",
      "--- Summary ---\n",
      "\n",
      "Total Issues: 1\n",
      "\n",
      "Total Issues By Severity:\n",
      "\n",
      "    - LOW: 0\n",
      "    - MEDIUM: 0\n",
      "    - HIGH: 0\n",
      "    - CRITICAL: 1\n",
      "\n",
      "--- Issues by Severity ---\n",
      "\n",
      "--- CRITICAL ---\n",
      "\n",
      "Unsafe operator found:\n",
      "  - Severity: CRITICAL\n",
      "  - Description: Use of unsafe operator 'system' from module 'nt'\n",
      "  - Source: C:\\Users\\simant.asawale\\Desktop\\ProtectAI\\modelscan\\notebooks\\XGBoostModels\\unsafe_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 18:06:54.422830: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-16 18:06:55.281508: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "!modelscan -p XGBoostModels/unsafe_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a908243",
   "metadata": {},
   "source": [
    "# Reporting Format\n",
    "ModelScan can report scan results in console (default), JSON, or custom report (to be defined by user in settings-file). For mode details, please see:  ` modelscan -h` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff858af",
   "metadata": {},
   "source": [
    "## JSON Report\n",
    "\n",
    "For JSON reporting: `modelscan -p ./path-to/file -r json -o output-file-name.json` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df55b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at /Users/mehrinkiani/Documents/modelscan/notebooks/modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning /Users/mehrinkiani/Documents/modelscan/notebooks/XGBoostModels/unsafe_model.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\u001b[1m{\u001b[0m\u001b[32m\"modelscan_version\"\u001b[0m: \u001b[32m\"0.5.0\"\u001b[0m, \u001b[32m\"timestamp\"\u001b[0m: \u001b[32m\"2024-01-25T17:56:00.855056\"\u001b[0m, \n",
      "\u001b[32m\"input_path\"\u001b[0m: \n",
      "\u001b[32m\"/Users/mehrinkiani/Documents/modelscan/notebooks/XGBoostModels/unsafe_model.pkl\u001b[0m\n",
      "\u001b[32m\"\u001b[0m, \u001b[32m\"total_issues\"\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m\"summary\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"total_issues_by_severity\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"LOW\"\u001b[0m: \u001b[1;36m0\u001b[0m, \n",
      "\u001b[32m\"MEDIUM\"\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m\"HIGH\"\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m\"CRITICAL\"\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m\"issues_by_severity\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"CRITICAL\"\u001b[0m: \n",
      "\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m\"description\"\u001b[0m: \u001b[32m\"Use of unsafe operator 'system' from module 'posix'\"\u001b[0m, \n",
      "\u001b[32m\"operator\"\u001b[0m: \u001b[32m\"system\"\u001b[0m, \u001b[32m\"module\"\u001b[0m: \u001b[32m\"posix\"\u001b[0m, \u001b[32m\"source\"\u001b[0m: \n",
      "\u001b[32m\"/Users/mehrinkiani/Documents/modelscan/notebooks/XGBoostModels/unsafe_model.pkl\u001b[0m\n",
      "\u001b[32m\"\u001b[0m, \u001b[32m\"scanner\"\u001b[0m: \u001b[32m\"modelscan.scanners.PickleUnsafeOpScan\"\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m\"errors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \n",
      "\u001b[32m\"scanned\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"total_scanned\"\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m\"scanned_files\"\u001b[0m: \n",
      "\u001b[1m[\u001b[0m\u001b[32m\"/Users/mehrinkiani/Documents/modelscan/notebooks/XGBoostModels/unsafe_model.pk\u001b[0m\n",
      "\u001b[32ml\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This will save the scan results in file: xgboost-model-scan-results.json\n",
    "!modelscan --path  XGBoostModels/unsafe_model.pkl -r json -o xgboost-model-scan-results.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(myenv)2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd638e2064d9001d4ca93bc8e56e039dad230900dd235e8a6196f1614960903a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
